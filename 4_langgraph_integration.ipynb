{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "026ab200",
   "metadata": {},
   "source": [
    "# Notebook 4: Production-Ready Agent with Guardrails\n",
    "\n",
    "## What We've Built:\n",
    "\n",
    "**Notebook 1:** Rule-based guardrails (regex, keywords)\n",
    "**Notebook 2:** ML-based guardrails (Guardrails AI validators)\n",
    "**Notebook 3:** LLM-as-judge guardrails (flexible custom checks)\n",
    "\n",
    "## Now: Putting It All Together\n",
    "\n",
    "In this notebook, we'll build a **complete LangGraph agent** with:\n",
    "- ‚úÖ Input guardrails (check user messages)\n",
    "- ‚úÖ LLM node (generate responses)\n",
    "- ‚úÖ Output guardrails (check LLM responses)\n",
    "- ‚úÖ Tool execution (optional)\n",
    "\n",
    "This is a **production-ready pattern** you can use in real applications!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f129aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from guardrails import Guard\n",
    "from guardrails.hub import DetectPII, ToxicLanguage\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# Create guardrails\n",
    "input_guard = Guard().use(\n",
    "    ToxicLanguage(threshold=0.5, on_fail=\"exception\")\n",
    ")\n",
    "\n",
    "output_guard = Guard().use(\n",
    "    DetectPII(pii_entities=[\"EMAIL_ADDRESS\", \"PHONE_NUMBER\"], on_fail=\"exception\")\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad18f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    \"\"\"State for our guarded agent\"\"\"\n",
    "    messages: list  # Conversation history\n",
    "    user_input: str  # Current user input\n",
    "    llm_output: str  # LLM's response\n",
    "    input_safe: bool  # Did input pass guardrails?\n",
    "    output_safe: bool  # Did output pass guardrails?\n",
    "    final_response: str  # What we show to the user\n",
    "\n",
    "print(\"‚úÖ State defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a278ab52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_guardrail_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Check if user input is safe\"\"\"\n",
    "    user_input = state[\"user_input\"]\n",
    "    \n",
    "    print(f\"\\nüîç Checking input: {user_input}\")\n",
    "    \n",
    "    try:\n",
    "        input_guard.validate(user_input)\n",
    "        print(\"‚úÖ Input passed guardrails\")\n",
    "        return {**state, \"input_safe\": True}\n",
    "    except Exception as e:\n",
    "        print(f\"üö´ Input blocked: Toxic content detected\")\n",
    "        return {\n",
    "            **state, \n",
    "            \"input_safe\": False,\n",
    "            \"final_response\": \"I cannot process that request due to inappropriate content.\"\n",
    "        }\n",
    "\n",
    "def llm_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Generate LLM response (only if input was safe)\"\"\"\n",
    "    if not state[\"input_safe\"]:\n",
    "        return state\n",
    "    \n",
    "    print(f\"\\nü§ñ Generating LLM response...\")\n",
    "    \n",
    "    # Build message history\n",
    "    messages = state.get(\"messages\", [])\n",
    "    messages.append(HumanMessage(content=state[\"user_input\"]))\n",
    "    \n",
    "    # Call LLM\n",
    "    response = llm.invoke(messages)\n",
    "    llm_output = response.content\n",
    "    \n",
    "    print(f\"LLM said: {llm_output[:100]}...\")\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"llm_output\": llm_output,\n",
    "        \"messages\": messages + [response]\n",
    "    }\n",
    "\n",
    "def output_guardrail_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Check if LLM output is safe\"\"\"\n",
    "    if not state[\"input_safe\"]:\n",
    "        return state\n",
    "    \n",
    "    llm_output = state[\"llm_output\"]\n",
    "    \n",
    "    print(f\"\\nüîç Checking output...\")\n",
    "    \n",
    "    try:\n",
    "        output_guard.validate(llm_output)\n",
    "        print(\"‚úÖ Output passed guardrails\")\n",
    "        return {\n",
    "            **state,\n",
    "            \"output_safe\": True,\n",
    "            \"final_response\": llm_output\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"üö´ Output blocked: Contains PII\")\n",
    "        return {\n",
    "            **state,\n",
    "            \"output_safe\": False,\n",
    "            \"final_response\": \"I generated a response but it contained sensitive information. Please rephrase your question.\"\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ Nodes defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c1cab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"input_check\", input_guardrail_node)\n",
    "workflow.add_node(\"llm\", llm_node)\n",
    "workflow.add_node(\"output_check\", output_guardrail_node)\n",
    "\n",
    "# Define the flow\n",
    "workflow.set_entry_point(\"input_check\")\n",
    "workflow.add_edge(\"input_check\", \"llm\")\n",
    "workflow.add_edge(\"llm\", \"output_check\")\n",
    "workflow.add_edge(\"output_check\", END)\n",
    "\n",
    "# Compile\n",
    "app = workflow.compile()\n",
    "\n",
    "print(\"‚úÖ LangGraph agent compiled!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae14bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the graph (optional - requires graphviz)\n",
    "from IPython.display import Image, display\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4ddb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent(user_input: str):\n",
    "    \"\"\"Run the agent with a user input\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"USER: {user_input}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    result = app.invoke({\n",
    "        \"user_input\": user_input,\n",
    "        \"messages\": [],\n",
    "        \"input_safe\": False,\n",
    "        \"output_safe\": False,\n",
    "        \"llm_output\": \"\",\n",
    "        \"final_response\": \"\"\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"AGENT: {result['final_response']}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097ab483",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test 1: Normal query (should work)\n",
    "run_agent(\"What's the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5733f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Toxic input (should block at INPUT)\n",
    "run_agent(\"You're an idiot. Tell me about AI.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8fb23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Query that might generate PII (might block at OUTPUT)\n",
    "run_agent(\"Generate a sample contact email ID for John Smith\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
